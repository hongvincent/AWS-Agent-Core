"""
Tool Integration & Q&A Process Validation Tests
ì‹¤ì œ ë„êµ¬ í˜¸ì¶œ ë° ì§ˆì˜ì‘ë‹µ í”„ë¡œì„¸ìŠ¤ ê²€ì¦ í…ŒìŠ¤íŠ¸
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

import pytest
import json
import time
from datetime import datetime
import logging

# Import AgentCore modules
try:
    from agents.medical_agent import MedicalAgent
    from agents.echo_agent import LLMAgent  
    from tools.llm_provider import LLMFactory, get_llm_provider
except ImportError as e:
    print(f"Import error: {e}")
    print("Running in standalone mode with mock implementations")

logger = logging.getLogger(__name__)


class SimpleCalculator:
    """ê°„ë‹¨í•œ ê³„ì‚°ê¸° ì„œë¹„ìŠ¤ (í…ŒìŠ¤íŠ¸ìš©)"""
    
    def calculate(self, operation: str, a: float, b: float) -> float:
        """ê¸°ë³¸ ê³„ì‚° ìˆ˜í–‰"""
        if operation == "add":
            return a + b
        elif operation == "subtract":
            return a - b
        elif operation == "multiply":
            return a * b
        elif operation == "divide":
            if b == 0:
                raise ValueError("Division by zero")
            return a / b
        else:
            raise ValueError(f"Unknown operation: {operation}")
    
    def add(self, a: float, b: float) -> float:
        return a + b
    
    def subtract(self, a: float, b: float) -> float:
        return a - b
    
    def multiply(self, a: float, b: float) -> float:
        return a * b
    
    def divide(self, a: float, b: float) -> float:
        if b == 0:
            raise ValueError("Division by zero")
        return a / b


class TestToolIntegration:
    """ì‹¤ì œ ë„êµ¬ í˜¸ì¶œ ë° í†µí•© í…ŒìŠ¤íŠ¸"""
    
    def setup_method(self):
        """ê° í…ŒìŠ¤íŠ¸ ì „ ì´ˆê¸°í™”"""
        try:
            self.provider = LLMFactory.create_provider()
        except:
            self.provider = None
        self.calculator = SimpleCalculator()
    
    def test_real_calculator_tool_integration(self):
        """ì‹¤ì œ ê³„ì‚°ê¸° ë„êµ¬ í˜¸ì¶œ í…ŒìŠ¤íŠ¸"""
        logger.info("=== ê³„ì‚°ê¸° ë„êµ¬ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        
        # ê¸°ë³¸ ê³„ì‚° í…ŒìŠ¤íŠ¸
        test_cases = [
            {"operation": "add", "a": 15, "b": 25, "expected": 40},
            {"operation": "multiply", "a": 7, "b": 8, "expected": 56},
            {"operation": "divide", "a": 100, "b": 4, "expected": 25},
            {"operation": "subtract", "a": 50, "b": 30, "expected": 20}
        ]
        
        results = []
        for case in test_cases:
            result = self.calculator.calculate(
                case["operation"], 
                case["a"], 
                case["b"]
            )
            
            success = result == case["expected"]
            results.append({
                "input": f"{case['a']} {case['operation']} {case['b']}",
                "expected": case["expected"],
                "actual": result,
                "success": success
            })
            
            logger.info(f"ê³„ì‚°: {case['a']} {case['operation']} {case['b']} = {result} ({'âœ…' if success else 'âŒ'})")
        
        # ëª¨ë“  ê³„ì‚°ì´ ì„±ê³µí–ˆëŠ”ì§€ ê²€ì¦
        all_success = all(r["success"] for r in results)
        assert all_success, f"ê³„ì‚°ê¸° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {results}"
        
        logger.info("âœ… ê³„ì‚°ê¸° ë„êµ¬ í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return results

    def test_medical_agent_tool_chain(self):
        """ì˜ë£Œ ì—ì´ì „íŠ¸ ë„êµ¬ ì²´ì¸ í…ŒìŠ¤íŠ¸"""
        logger.info("=== ì˜ë£Œ ì—ì´ì „íŠ¸ ë„êµ¬ ì²´ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        
        agent = MedicalAgent()
        
        # ë„êµ¬ ì²´ì¸ ì‹œë‚˜ë¦¬ì˜¤: ìƒë‹´ â†’ ì§„ë£Œê³¼ ì¶”ì²œ â†’ ì˜ˆì•½ í™•ì¸ â†’ ì‘ê¸‰ ê°ì§€
        scenarios = [
            {
                "step": 1,
                "input": "ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” 30ì„¸ ì—¬ì„±ì´ê³  ì„ì‹  8ì£¼ì°¨ì…ë‹ˆë‹¤.",
                "expected_tools": ["patient_context_extraction", "department_recommendation"],
                "expected_department": "ì‚°ë¶€ì¸ê³¼"
            },
            {
                "step": 2, 
                "input": "ì •ê¸° ê²€ì§„ì„ ë°›ê³  ì‹¶ì–´ìš”. ì–¸ì œ ì˜ˆì•½ ê°€ëŠ¥í•œê°€ìš”?",
                "expected_tools": ["appointment_availability", "booking_system"],
                "expected_response_contains": ["ì˜ˆì•½", "ê°€ëŠ¥"]
            },
            {
                "step": 3,
                "input": "ê°‘ìê¸° ë°°ê°€ ë„ˆë¬´ ì•„íŒŒìš”! ì¶œí˜ˆë„ ìˆì–´ìš”!",
                "expected_tools": ["emergency_detection", "emergency_protocol"],
                "expected_status": "emergency_detected"
            }
        ]
        
        conversation_flow = []
        
        for scenario in scenarios:
            logger.info(f"Step {scenario['step']}: {scenario['input']}")
            
            start_time = time.time()
            result = agent.process_message(scenario["input"])
            process_time = time.time() - start_time
            
            conversation_flow.append({
                "step": scenario["step"],
                "input": scenario["input"],
                "output": result["output"],
                "department": result.get("department_recommended"),
                "status": result.get("status"),
                "process_time": process_time,
                "patient_context": agent.patient_context
            })
            
            # ì‘ê¸‰ìƒí™© ê°ì§€ ê²€ì¦
            if "expected_status" in scenario:
                if scenario["expected_status"] == "emergency_detected":
                    emergency_check = agent._check_emergency_symptoms(scenario["input"])
                    assert emergency_check["is_emergency"], f"ì‘ê¸‰ìƒí™© ë¯¸ê°ì§€: {scenario['input']}"
                    logger.info(f"ğŸš¨ ì‘ê¸‰ìƒí™© ì •ìƒ ê°ì§€: {emergency_check['detected_keywords']}")
            
            # ì§„ë£Œê³¼ ì¶”ì²œ ê²€ì¦  
            if "expected_department" in scenario:
                department = result.get("department_recommended")
                if department and scenario["expected_department"] in str(department):
                    logger.info(f"âœ… ì§„ë£Œê³¼ ì¶”ì²œ ì„±ê³µ: {department}")
                else:
                    logger.warning(f"âš ï¸ ì§„ë£Œê³¼ ì¶”ì²œ í™•ì¸ í•„ìš”: {department}")
            
            logger.info(f"ì²˜ë¦¬ ì‹œê°„: {process_time:.2f}ì´ˆ")
        
        # ëŒ€í™” ì—°ì†ì„± ê²€ì¦
        final_context = agent.patient_context
        assert "gender" in final_context or "age" in final_context, "í™˜ì ì»¨í…ìŠ¤íŠ¸ ëˆ„ì  ì‹¤íŒ¨"
        
        logger.info("âœ… ì˜ë£Œ ì—ì´ì „íŠ¸ ë„êµ¬ ì²´ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return conversation_flow

    def test_qna_process_multi_turn(self):
        """ë‹¤ì¤‘ í„´ Q&A í”„ë¡œì„¸ìŠ¤ í…ŒìŠ¤íŠ¸"""
        logger.info("=== ë‹¤ì¤‘ í„´ Q&A í”„ë¡œì„¸ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        
        agent = LLMAgent()
        
        # ë³µí•©ì ì¸ Q&A ì‹œë‚˜ë¦¬ì˜¤
        qna_sequence = [
            {
                "q": "ì•ˆë…•í•˜ì„¸ìš”. AgentCoreì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.",
                "expected_keywords": ["agentcore", "ai", "ì–´ì‹œìŠ¤í„´íŠ¸"]
            },
            {
                "q": "LLM í†µí•©ì€ ì–´ë–»ê²Œ ë˜ì–´ìˆë‚˜ìš”?", 
                "expected_keywords": ["llm", "í†µí•©", "openai", "bedrock"]
            },
            {
                "q": "ì˜ë£Œ ë„ë©”ì¸ íŠ¹í™” ê¸°ëŠ¥ì´ ìˆë‚˜ìš”?",
                "expected_keywords": ["ì˜ë£Œ", "ë„ë©”ì¸", "íŠ¹í™”", "ê¸°ëŠ¥"]
            },
            {
                "q": "ì•ì„œ ì§ˆë¬¸í•œ ë‚´ìš©ë“¤ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.",
                "expected_keywords": ["agentcore", "llm", "ì˜ë£Œ", "ìš”ì•½"]
            }
        ]
        
        conversation_history = []
        context_continuity_scores = []
        
        for i, qna in enumerate(qna_sequence):
            logger.info(f"Q{i+1}: {qna['q']}")
            
            start_time = time.time()
            result = agent.process_message(qna["q"])
            response_time = time.time() - start_time
            
            answer = result["output"]
            logger.info(f"A{i+1}: {answer[:100]}...")
            
            # í‚¤ì›Œë“œ í¬í•¨ ê²€ì¦
            keyword_matches = []
            for keyword in qna["expected_keywords"]:
                if keyword.lower() in answer.lower():
                    keyword_matches.append(keyword)
            
            keyword_score = len(keyword_matches) / len(qna["expected_keywords"])
            
            # ëŒ€í™” ì—°ì†ì„± ì ìˆ˜ (ì´ì „ ëŒ€í™” ë‚´ìš© ì°¸ì¡°í•˜ëŠ”ì§€)
            if i > 0:  # ë‘ ë²ˆì§¸ ì§ˆë¬¸ë¶€í„°
                previous_keywords = []
                for prev_qna in conversation_history:
                    previous_keywords.extend(prev_qna["keywords_found"])
                
                continuity_count = sum(1 for kw in previous_keywords if kw in answer.lower())
                continuity_score = min(continuity_count / len(previous_keywords), 1.0) if previous_keywords else 0
                context_continuity_scores.append(continuity_score)
            else:
                continuity_score = 1.0  # ì²« ë²ˆì§¸ ì§ˆë¬¸ì€ ë§Œì 
            
            conversation_turn = {
                "turn": i + 1,
                "question": qna["q"],
                "answer": answer,
                "response_time": response_time,
                "expected_keywords": qna["expected_keywords"],
                "keywords_found": keyword_matches,
                "keyword_score": keyword_score,
                "continuity_score": continuity_score,
                "timestamp": datetime.now().isoformat()
            }
            
            conversation_history.append(conversation_turn)
            
            logger.info(f"í‚¤ì›Œë“œ ì ìˆ˜: {keyword_score:.2f}, ì—°ì†ì„± ì ìˆ˜: {continuity_score:.2f}, ì‘ë‹µì‹œê°„: {response_time:.2f}ì´ˆ")
        
        # ì „ì²´ Q&A í”„ë¡œì„¸ìŠ¤ í‰ê°€
        avg_keyword_score = sum(t["keyword_score"] for t in conversation_history) / len(conversation_history)
        avg_continuity_score = sum(context_continuity_scores) / len(context_continuity_scores) if context_continuity_scores else 1.0
        avg_response_time = sum(t["response_time"] for t in conversation_history) / len(conversation_history)
        
        logger.info(f"=== Q&A í”„ë¡œì„¸ìŠ¤ ìµœì¢… í‰ê°€ ===")
        logger.info(f"í‰ê·  í‚¤ì›Œë“œ ì í•©ì„±: {avg_keyword_score:.2f}")
        logger.info(f"í‰ê·  ëŒ€í™” ì—°ì†ì„±: {avg_continuity_score:.2f}") 
        logger.info(f"í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_response_time:.2f}ì´ˆ")
        
        # í’ˆì§ˆ ê¸°ì¤€ ê²€ì¦
        assert avg_keyword_score >= 0.5, f"í‚¤ì›Œë“œ ì í•©ì„± ë¶€ì¡±: {avg_keyword_score}"
        assert avg_continuity_score >= 0.3, f"ëŒ€í™” ì—°ì†ì„± ë¶€ì¡±: {avg_continuity_score}"
        assert avg_response_time <= 10.0, f"ì‘ë‹µ ì‹œê°„ ì´ˆê³¼: {avg_response_time}ì´ˆ"
        
        logger.info("âœ… ë‹¤ì¤‘ í„´ Q&A í”„ë¡œì„¸ìŠ¤ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return {
            "conversation_history": conversation_history,
            "metrics": {
                "avg_keyword_score": avg_keyword_score,
                "avg_continuity_score": avg_continuity_score,
                "avg_response_time": avg_response_time
            }
        }

    def test_end_to_end_workflow(self):
        """ì—”ë“œíˆ¬ì—”ë“œ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
        logger.info("=== ì—”ë“œíˆ¬ì—”ë“œ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        
        # ì‹¤ì œ ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤: ì˜ë£Œìƒë‹´ + ê³„ì‚° + Q&A
        workflow_steps = []
        
        # Step 1: ì˜ë£Œ ìƒë‹´ ì‹œì‘
        medical_agent = MedicalAgent()
        step1_result = medical_agent.process_message("ì•ˆë…•í•˜ì„¸ìš”. í˜ˆì••ì´ 140/90 ì •ë„ ë‚˜ì™€ì„œ ê±±ì •ë©ë‹ˆë‹¤.")
        
        workflow_steps.append({
            "step": "ì˜ë£Œ_ìƒë‹´_ì‹œì‘",
            "agent": "MedicalAgent", 
            "input": "í˜ˆì•• 140/90 ìƒë‹´ ìš”ì²­",
            "output": step1_result["output"][:100] + "...",
            "tools_used": ["patient_context_extraction", "department_recommendation"],
            "success": step1_result["status"] == "success"
        })
        
        # Step 2: ê³„ì‚°ê¸°ë¡œ BMI ê³„ì‚° (ì˜ˆì‹œ)
        bmi_calculation = self.calculator.divide(70, 1.75)  # weight / height^2 approximation
        bmi_result = self.calculator.multiply(bmi_calculation, 0.57)  # ëŒ€ëµì ì¸ BMI
        
        workflow_steps.append({
            "step": "BMI_ê³„ì‚°",
            "agent": "CalculatorService",
            "input": "ì²´ì¤‘ 70kg, í‚¤ 175cm",
            "output": f"BMI ì¶”ì •ê°’: {bmi_result:.1f}",
            "tools_used": ["divide", "multiply"],
            "success": bmi_result > 0
        })
        
        # Step 3: LLM ì—ì´ì „íŠ¸ë¡œ ì¢…í•© ìƒë‹´
        llm_agent = LLMAgent()
        comprehensive_query = f"í˜ˆì•• 140/90ì´ê³  BMIê°€ {bmi_result:.1f} ì •ë„ì¸ë° ì–´ë–¤ ê´€ë¦¬ê°€ í•„ìš”í• ê¹Œìš”?"
        step3_result = llm_agent.process_message(comprehensive_query)
        
        workflow_steps.append({
            "step": "ì¢…í•©_ìƒë‹´",
            "agent": "LLMAgent",
            "input": comprehensive_query,
            "output": step3_result["output"][:100] + "...",
            "tools_used": ["llm_integration", "context_analysis"],
            "success": step3_result["status"] == "success"
        })
        
        # Step 4: ì˜ë£Œ ì—ì´ì „íŠ¸ë¡œ ì˜ˆì•½ ì²˜ë¦¬
        appointment_result = medical_agent.process_message("ë‚´ê³¼ ì˜ˆì•½ì„ í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.")
        
        workflow_steps.append({
            "step": "ì˜ˆì•½_ì²˜ë¦¬", 
            "agent": "MedicalAgent",
            "input": "ë‚´ê³¼ ì˜ˆì•½ ìš”ì²­",
            "output": appointment_result["output"][:100] + "...",
            "tools_used": ["appointment_booking", "availability_check"],
            "success": appointment_result["status"] == "success"
        })
        
        # ì›Œí¬í”Œë¡œìš° ì„±ê³µë¥  ê³„ì‚°
        successful_steps = sum(1 for step in workflow_steps if step["success"])
        success_rate = successful_steps / len(workflow_steps)
        
        logger.info(f"=== ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼ ===")
        for i, step in enumerate(workflow_steps, 1):
            status = "âœ…" if step["success"] else "âŒ"
            logger.info(f"{i}. {step['step']} ({step['agent']}): {status}")
            logger.info(f"   ë„êµ¬: {', '.join(step['tools_used'])}")
            logger.info(f"   ê²°ê³¼: {step['output']}")
        
        logger.info(f"ì „ì²´ ì„±ê³µë¥ : {success_rate:.2%} ({successful_steps}/{len(workflow_steps)})")
        
        # ìµœì†Œ 80% ì„±ê³µë¥  ìš”êµ¬
        assert success_rate >= 0.8, f"ì›Œí¬í”Œë¡œìš° ì„±ê³µë¥  ë¶€ì¡±: {success_rate:.2%}"
        
        logger.info("âœ… ì—”ë“œíˆ¬ì—”ë“œ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return {
            "workflow_steps": workflow_steps,
            "success_rate": success_rate,
            "total_steps": len(workflow_steps),
            "successful_steps": successful_steps
        }


class TestProcessValidation:
    """í”„ë¡œì„¸ìŠ¤ ê²€ì¦ ë° í’ˆì§ˆ ì¸¡ì •"""
    
    def test_response_quality_metrics(self):
        """ì‘ë‹µ í’ˆì§ˆ ë©”íŠ¸ë¦­ ì¸¡ì •"""
        logger.info("=== ì‘ë‹µ í’ˆì§ˆ ë©”íŠ¸ë¦­ ì¸¡ì • ì‹œì‘ ===")
        
        agent = LLMAgent()
        
        # ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì§ˆë¬¸ìœ¼ë¡œ í’ˆì§ˆ ì¸¡ì •
        test_queries = [
            {"type": "factual", "query": "AgentCoreì˜ ì£¼ìš” ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?"},
            {"type": "technical", "query": "LLM Provider ì•„í‚¤í…ì²˜ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."},
            {"type": "conversational", "query": "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë– ì„¸ìš”?"},
            {"type": "problem_solving", "query": "Pythonì—ì„œ ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°ì„ ì–´ë–»ê²Œ êµ¬í˜„í•˜ë‚˜ìš”?"}
        ]
        
        quality_metrics = []
        
        for test in test_queries:
            start_time = time.time()
            result = agent.process_message(test["query"])
            response_time = time.time() - start_time
            
            response = result["output"]
            
            # í’ˆì§ˆ ì§€í‘œ ê³„ì‚°
            metrics = {
                "query_type": test["type"],
                "query": test["query"],
                "response_length": len(response),
                "response_time": response_time,
                "has_greeting": any(greeting in response.lower() for greeting in ["ì•ˆë…•", "hello", "ë°˜ê°‘"]),
                "has_explanation": len(response.split('.')) > 2,
                "politeness_score": sum(1 for word in ["ì£¼ì„¸ìš”", "ìŠµë‹ˆë‹¤", "í•´ìš”", "ì…ë‹ˆë‹¤"] if word in response) / 4,
                "technical_terms": sum(1 for term in ["api", "llm", "agent", "provider"] if term.lower() in response.lower()),
                "completeness_score": min(len(response) / 100, 1.0)  # 100ìë‹¹ 0.1ì , ìµœëŒ€ 1.0
            }
            
            quality_metrics.append(metrics)
            
            logger.info(f"ì§ˆë¬¸ ìœ í˜•: {test['type']}")
            logger.info(f"ì‘ë‹µ ê¸¸ì´: {metrics['response_length']}ì, ì‹œê°„: {response_time:.2f}ì´ˆ")
            logger.info(f"ì™„ì„±ë„: {metrics['completeness_score']:.2f}, ì •ì¤‘í•¨: {metrics['politeness_score']:.2f}")
        
        # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        avg_completeness = sum(m["completeness_score"] for m in quality_metrics) / len(quality_metrics)
        avg_politeness = sum(m["politeness_score"] for m in quality_metrics) / len(quality_metrics)
        avg_response_time = sum(m["response_time"] for m in quality_metrics) / len(quality_metrics)
        
        logger.info(f"=== í’ˆì§ˆ ë©”íŠ¸ë¦­ ì¢…í•© ===")
        logger.info(f"í‰ê·  ì™„ì„±ë„: {avg_completeness:.2f}")
        logger.info(f"í‰ê·  ì •ì¤‘í•¨: {avg_politeness:.2f}")
        logger.info(f"í‰ê·  ì‘ë‹µì‹œê°„: {avg_response_time:.2f}ì´ˆ")
        
        # í’ˆì§ˆ ê¸°ì¤€ ê²€ì¦
        assert avg_completeness >= 0.6, f"ì‘ë‹µ ì™„ì„±ë„ ë¶€ì¡±: {avg_completeness}"
        assert avg_response_time <= 10.0, f"ì‘ë‹µ ì‹œê°„ ì´ˆê³¼: {avg_response_time}ì´ˆ"  # LLM ì‘ë‹µ ì‹œê°„ì„ í˜„ì‹¤ì ìœ¼ë¡œ ì¡°ì •
        
        logger.info("âœ… ì‘ë‹µ í’ˆì§ˆ ë©”íŠ¸ë¦­ ì¸¡ì • ì™„ë£Œ")
        return quality_metrics

    def test_error_handling_robustness(self):
        """ì˜¤ë¥˜ ì²˜ë¦¬ ê²¬ê³ ì„± í…ŒìŠ¤íŠ¸"""
        logger.info("=== ì˜¤ë¥˜ ì²˜ë¦¬ ê²¬ê³ ì„± í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        
        medical_agent = MedicalAgent()
        
        # ë‹¤ì–‘í•œ ì˜¤ë¥˜ ìƒí™© ì‹œë®¬ë ˆì´ì…˜
        error_scenarios = [
            {"input": "", "expected": "ì…ë ¥ ì—†ìŒ ì²˜ë¦¬"},
            {"input": "a" * 1000, "expected": "ê¸´ ì…ë ¥ ì²˜ë¦¬"},
            {"input": "!@#$%^&*()", "expected": "íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬"},
            {"input": "SQL injection'; DROP TABLE users;--", "expected": "ì•…ì˜ì  ì…ë ¥ ì²˜ë¦¬"},
            {"input": "undefined function call", "expected": "ì˜ëª»ëœ ìš”ì²­ ì²˜ë¦¬"}
        ]
        
        error_handling_results = []
        
        for scenario in error_scenarios:
            logger.info(f"ì˜¤ë¥˜ ì‹œë‚˜ë¦¬ì˜¤: {scenario['input'][:50]}...")
            
            try:
                result = medical_agent.process_message(scenario["input"])
                
                # ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ì ì ˆí•œ ì‘ë‹µì„ ë°˜í™˜í•˜ëŠ”ì§€ í™•ì¸
                has_output = "output" in result and result["output"]
                has_fallback = "ì£„ì†¡í•©ë‹ˆë‹¤" in result["output"] or "ì˜¤ë¥˜" in result["output"]
                no_crash = True
                
            except Exception as e:
                logger.warning(f"ì˜ˆì™¸ ë°œìƒ: {str(e)}")
                has_output = False
                has_fallback = False  
                no_crash = False
                result = {"error": str(e)}
            
            error_result = {
                "scenario": scenario["input"][:50],
                "expected": scenario["expected"],
                "has_output": has_output,
                "has_fallback": has_fallback,
                "no_crash": no_crash,
                "result": result.get("output", result.get("error", ""))[:100]
            }
            
            error_handling_results.append(error_result)
            
            status = "âœ…" if (has_output and no_crash) else "âŒ"
            logger.info(f"ì²˜ë¦¬ ê²°ê³¼: {status}")
        
        # ê²¬ê³ ì„± ì ìˆ˜ ê³„ì‚°
        robustness_scores = []
        for result in error_handling_results:
            score = sum([
                int(result["has_output"]) * 0.4,
                int(result["has_fallback"]) * 0.3, 
                int(result["no_crash"]) * 0.3
            ])
            robustness_scores.append(score)
        
        avg_robustness = sum(robustness_scores) / len(robustness_scores)
        
        logger.info(f"í‰ê·  ê²¬ê³ ì„± ì ìˆ˜: {avg_robustness:.2f}")
        
        # ìµœì†Œ 70% ê²¬ê³ ì„± ìš”êµ¬
        assert avg_robustness >= 0.7, f"ì˜¤ë¥˜ ì²˜ë¦¬ ê²¬ê³ ì„± ë¶€ì¡±: {avg_robustness}"
        
        logger.info("âœ… ì˜¤ë¥˜ ì²˜ë¦¬ ê²¬ê³ ì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return error_handling_results


if __name__ == "__main__":
    # ë¹ ë¥¸ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("=== AWS AgentCore Tool & Q&A Process Validation ===")
    
    # Tool Integration Test
    tool_tester = TestToolIntegration()
    tool_tester.setup_method()
    
    print("\n1. ê³„ì‚°ê¸° ë„êµ¬ í…ŒìŠ¤íŠ¸")
    calc_results = tool_tester.test_real_calculator_tool_integration()
    
    print("\n2. ì˜ë£Œ ì—ì´ì „íŠ¸ ë„êµ¬ ì²´ì¸ í…ŒìŠ¤íŠ¸")
    medical_results = tool_tester.test_medical_agent_tool_chain()
    
    print("\n3. Q&A í”„ë¡œì„¸ìŠ¤ í…ŒìŠ¤íŠ¸")
    qna_results = tool_tester.test_qna_process_multi_turn()
    
    print("\n4. ì—”ë“œíˆ¬ì—”ë“œ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸")
    workflow_results = tool_tester.test_end_to_end_workflow()
    
    # Process Validation Test
    print("\n5. ì‘ë‹µ í’ˆì§ˆ ê²€ì¦")
    process_tester = TestProcessValidation()
    quality_results = process_tester.test_response_quality_metrics()
    
    print("\n6. ì˜¤ë¥˜ ì²˜ë¦¬ ê²¬ê³ ì„± ê²€ì¦")
    robustness_results = process_tester.test_error_handling_robustness()
    
    print("\n=== ì¢…í•© ê²€ì¦ ì™„ë£Œ ===")
    print("âœ… ëª¨ë“  Tool í˜¸ì¶œ ë° Q&A í”„ë¡œì„¸ìŠ¤ê°€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤!")